\section{Related Work}
\label{related_work}
Using Large Language Models (LLMs) to extract event logs from natural language text (NLT) combines the complexity of several research disciplines: Natural Language Processing (NLP), Information Extraction (IE), Prompt Engineering, Modelling (wherein the configuration of event logs is a design decision), Software Engineering and LLM-training.\\
In this bachelor thesis, we focus explicitly on the aspect of fine-tuning and the specific application of all these disciplines to extracting event logs from patient journeys. This use-case has been relatively under-researched and is currently not documented.\\\\
In essence, the extraction of event logs from patient journeys is an Information Extraction (IE) task. IE tasks aim at extracting information from unstructured plain text. Han et al.~\cite{han_is_2023} conducted extensive research on how well ChatGPT performs in IE tasks. The outcome revealed that, even with the usage of all common prompt engineering approaches (e.g. Few, Shot, Chain of Thought), ChatGPT lags considerably behind State-of-the-Art methods. Outcomes are even worse – up to 48\% – when irrelevant information for the task is included in the context.\\
Bahak et al.~\cite{bahak_evaluating_2023} also emphasized, that ChatGPT 3.5 turbo often hallucinates by giving context-related responses to questions, even though the given context does not contain an answer. This problem is also encountered when extracting from patient journeys due to often missing information, particularly time specifics. Hence, it's investigated in this study if the problem could be mitigated by fine-tuning.\\\\
Ovadia et al.~\cite{ovadia_fine-tuning_2024} explored various fine-tuning strategies (mainly unsupervised fine-tuning (USFT) and retrieval-augmented generation (RAG)) aiming to improve the processing of knowledge-based tasks. It was discovered that knowledge-based tasks could be significantly improved using fine-tuned models, but USFT is less suitable for knowledge injection than RAG. Contrarily, my approach aims to enhance the model's output not by adding more knowledge, but by helping the model to better understand the complex task at hand. Therefore, my pursuit requires different demands on fine-tuning strategies.\\\\
\newpage
Latif et al.~\cite{latif_fine-tuning_2024} explored the potentials of fine-tuned ChatGPT in the area of automated scoring of students' written work. They employed a large, diverse dataset to train their model. The result showed the outcomes were not only better than those of non-fine-tuned ChatGPT, but also surpassed the performance of the then best publicly available model, BERT. The tasks to be corrected were single and multi-label tasks, so primarily multiple-choice questions. This bachelor thesis also deals with tasks where there are no predefined answer options. These tasks are even harder for the model to complete correctly and also require a different approach in evaluation.\\\\
In other research areas such as Caption Rewrites, News~\cite{gladkoff_predictive_2023} Recommendations~\cite{li_exploring_2023}, or Machine Translation Evaluation~\cite{wang_mitigating_2023}, it was also confirmed that the application of fine-tuned models led to improved results.\\\\
A common thread in these studies is the utilization of large, well-established datasets. Extracting event logs from NLT, or patient journeys specifically, is still a niche sector in which such datasets do not exist. Hence, the compilation of these datasets is also a part of this Bachelor's Thesis.\\\\
In short: ChatGPT 3.5 turbo in itself is not very adapt at performing IE-tasks and suffers greatly from too large context. Depending on the goal, different fine-tuning strategies might be better suited to customize an LLM in the desired way. The increased performance of fine-tuned pre-trained transformer models in various fields of study is promising. However, the fact remains, that extracting event logs from NLT involves problems that were not tackled before. The ambition of this bachelor thesis is to extend the aforementioned findings and determine if fine-tuning can resolve IE-task problems by applying training strategies. The objective of extracting high-quality event logs from patient journeys is used as an example throughout this thesis, as it is the focus of the underlying tool TracEX.