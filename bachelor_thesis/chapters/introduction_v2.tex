\section{Introduction}\label{sec:intro}
Over recent years, Process Mining has proven to be a powerful tool for detecting, analysing, and optimising (business) processes~\cite{weske_business_2012}. Its operation is fundamentally reliant on event logs, which traditionally are generated automatically within Information Systems.\\
However, with the rise of large language models (LLMs), interest in processing unstructured data has increased considerably. It opens up entirely new possibilities to analyze not only structured data from companies and healthcare systems, for example, but also non-standard reports from individuals. These could range from analysing conversations from social media platforms such as Reddit or Facebook to specifically requested reports that do not adhere to a strict format, making them easier for people to produce.\\
Consequently, there is a crucial need to convert unstructured data into event logs, which are necessary to apply process mining.
\\
For example, the LLM-based project TracEX~\footnote{https://github.com/bptlab/TracEX} aims to extract event logs from patient-written descriptions of disease courses in order to provide researchers with valuable process information. It plays an essential role in this thesis, as we intend to improve it by providing fine-tuned models.\\
There are significant challenges in sourcing and preparing data for Process Mining, even when using traditional data sources~\cite{van_der_aalst_process_2016}. From a practical standpoint, data quality is paramount for successful Process Mining. Any missing or untrustworthy event data severely undermines the value of the results obtained. 
\begin{quote}
    \quotes{From a practical point of view data quality is of the utmost importance for the success of process mining. If event data is missing or cannot be trusted, then the results of process mining are less valuable.}~\cite{van_der_aalst_process_2016}    
\end{quote}
These problems persist when using unstructured text as a data source. Furthermore, the data has to be structured, complicating matters even more. Non-standardised, manually added data,  written by laypeople without any claim for completeness or readability, are even more prone to the issues faced with traditional data sources.\\
In the past, attempts have been made to process this type of data, including in the realm of process modelling~\cite{friedrich_process_2011}. Aside from human manual extraction,  deterministic Natural Language Processing (NLP) approaches have been used. Unfortunately, these attempts quickly met limitations, particularly in deriving temporal relationships between events.\\
Recently, there has been an explosive rise in the field of Generative AI and LLMs in general. Transformer models from OpenAI, for instance, have proven to be powerful tools in various applications due to their ability to comprehend human language and respond in kind. This fact suggests that these models can also process textual disease course descriptions, for example, and be utilized to extract event logs from them.\\
However, the use of LLMs introduces additional challenges. They are non-deterministic, meaning the same input can yield different outputs. Furthermore, their operation mechanisms are not transparent and, therefore, not entirely understood. Making them carry out tasks exactly as desired requires significant trial and error. For event logs, the quality and formatting of the collected data are vital. The data must not only be extracted accurately and completely but also cast into the appropriate format (such as XES).
These and many other hurdles pose substantial difficulties in event log extraction~\cite{munoz-gama_process_2022}. Established Transformer models, such as those from OpenAI, struggle to overcome these issues. Therefore, research has been conducted to explore ways to fine-tune these general-purpose models for specific tasks or topics. This work investigates the extent to which fine-tuning could solve these problems and create high-quality event logs. As stated by~\cite{latif_fine-tuning_2024}, 
\begin{quote}
\quotes{Fine-tuned GPT models are more suited to tasks like text completion, response evaluation, or open-ended queries because of their autoregressive nature, which excels in sequence formation.} 
\end{quote}

This thesis is structured as follows:\\
\hyperref[sec:back]{Section~\ref*{sec:back}} introduces the preliminaries followed by \autoref{sec:related_work}, situating this thesis among other studies. \hyperref[sec:fine]{Section~\ref*{sec:fine}} explores different approaches to fine-tuning and describes the compilation of training data. In \autoref{sec:eval}, we evaluate the performance of the trained models after introducing the required metrics. The thesis concludes with \autoref{sec:discussion} and \autoref{sec:conclusion}, summarising findings, discussing the limitations and providing an outlook for future work.