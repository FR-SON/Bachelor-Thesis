\section{Fine-Tuning Strategies}\label{sec:fine}
In the following chapters, we will present an approach to fine-tuning GPT-3.5 Turbo, which is specialized for extracting event logs from Patient Journeys. We will use four of the steps used in TracEX to demonstrate: Extracting activity labels, classifying event types, extracting start timestamps and extracting end timestamps. Part of that approach is preparing the datasets for training and validating the model. This is mainly because the desired application is a niche subject, resulting in a lack of large, established datasets. Curating and assembling the training data is a time-consuming yet crucial task in fine-tuning an LLM.\\\\
Since we use GPT-3.5 Turbo and the corresponding tools from OpenAI, the set of applicable fine-tuning strategies is limited. As mentioned in \ref{sec:fine-tuning-def}, there are fundamentally three potentially interesting strategies: Supervised fine-tuning (SFT), unsupervised fine-tuning and reinforcement learning. The fine-tuning framework OpenAI provides is focused on SFT, so we also focus on that. Fittingly, SFT is said to be suited for improving a model's understanding of complex tasks and increasing the reliability of correctly formatted responses, which is the purpose we use fine-tuning for.\\
Another dimension in which one can differentiate fine-tuning strategies is the number of tasks a model is fine-tuned for.\\
\emph{Multi-task fine-tuning} means training a model on multiple related tasks simultaneously – within one dataset. By leveraging the commonalities of the tasks, the model can learn and understand quicker, decreasing the number of examples it needs to increase its performance in all the tasks.~\cite{pilault_conditionally_2020}\\
\emph{Task-specific fine-tuning}, on the other hand, means training a model for only one well-defined, isolated task. This enables an even more refined understanding of the intricate details of one specific task. Especially with very complex tasks or those that require a deeper understanding of the domain, this method excels.~\cite{xinxi_single_2021}\\\\
The individual steps included in the extraction framework of TracEX can be categorized into different types of tasks. Each type poses different challenges and has a different complexity. Classifying event types requires the GPT to select the correct answer from a predefined set of choices. On top of that, the given context is relatively small. Determining the relevant activities is a much more complex task, and the GPT's response is only limited by the number of words that should represent one activity. The exact words that make up the activity are up to the GPT to decide. The context for that task is larger as well since all sentences have to be examined in the context in order to determine which activities are relevant and which descriptions make up one event in the Patient Journey. Deriving timestamps for activities is, without a doubt, the most challenging task. Not only is temporal information often hardly present or missing altogether in real-world Patient Journeys, but it can also take many shapes. 'On 2024/04/02', 'at the beginning of August', 'On Tuesday', 'In autumn', 'As the week progressed', and 'Later' are all examples from real-world Patient Journeys that need to be converted into XES-conform timestamps. So, adding to all the challenges involved in this type of task is the requirement for correct formatting.

\subsection{Multi-task fine-tuning}\label{sec:multi-task-ft}
In this chapter, we will describe the process of multi-task fine-tuning GPT-3.5 Turbo for all the mentioned tasks – labelling activities, classifying event types,  determining start timestamps and determining end timestamps. This strategy counteracts the fact that the size of the datasets will always be relatively small compared to the datasets used in the work presented in ~\autoref{related_work}. Examples that explain the classification of event types, for instance, take activity labels as input, which means this step also profits from the examples for extracting activity labels because we present more possible activity labels throughout the training process. The underlying task in all steps is to understand, extract and transform information from a text. This makes it a valuable approach.

\subsubsection{Curating Datasets}\label{sec:curating_data}
We structure this chapter into three paragraphs. Each paragraph describes one of the message types we need in our fine-tuning training data, starting with system messages, then user messages, and finally, assistant messages. Furthermore, each paragraph sequentially describes the characteristics of the different messages for activity labelling, start and end timestamp extraction, and event type classification.
\paragraph{System Messages:} The system message is, in most cases, identical to the system prompt used in TracEX – for two reasons:
\begin{enumerate}
    \item
        The prompts are complex, specifying the thought process the model should take, the response format, and the aspects of the input to focus on. Showing the model how to respond to these specific instructions underlines the connection between the details of the instructions and the desired output. For example, suppose the instruction includes \quotes{Answer, using only one word.} and the assistant message contains only one word. In that case, it should be easier for the model to understand how to action this instruction in the future. Thus, the training data prepares the model for the exact instructions we will prompt it with.\\
        The drawback of this approach is that we can not shorten the prompts used with the fine-tuned model as much. They still need to contain every specification that is necessary for the base model. On the other hand, this makes the model more flexible: If a prompt contains special instructions, the model will implement them. If a prompt does not contain special instructions, no predefined formatting or similar customizations will be present in the response.\\
        Teaching a model to behave in a certain way purely by examples – omitting the explanations in the system messages but keeping the output the same – can also work. However, because the fine-tuned model has no connections between the instructions and the demanded behaviour, it will always behave like the examples taught it to, making it less flexible. That is why we do not choose this approach.
    \item 
        Showing the model the exact same instruction repeatedly should result in the model being primed to fulfil that task without being 'distracted' by other possible instructions. It knows only this one task, to exaggerate. Of course, a pre-trained model like GPT-3.5 Turbo has vast knowledge about various other tasks. Fine-tuning only changes the model on the surface level. Still, we need to consider this, which is why we propose keeping the system prompts close to the ones that will be used with the fine-tuned model.
\end{enumerate}
\autoref{lst:system:starttime} shows what a system message can look like.

\begin{lstlisting}[language=json, caption={System message for determining an activities start timestamp}, label={lst:system:starttime}]
{"role":"system",
 "content":"You are an expert in text understanding and your job is to take a given text and a given activity label and to extract a start date to this activity label. Only output the extracted start date! Rely on the context to determine the start date, as it might not be explicitly mentioned."
}
\end{lstlisting}

\paragraph{User messages:}\label{par:user-messages} Sample tasks in the user-messages should also be similar to the ones the fine-tuned model will face in reality. The training data contains example inputs like they are described in \autoref{sec:tracex}:\\
Training data for the activity labelling step is an entire patient journey. The goal is to convey which parts of the huge context are important. In order to demonstrate which aspects to keep and which to discard in the assistant-message, the entire journey is necessary.\\
To illustrate, assume a patient journey contains the following paragraph:
\begin{quote}
    \quotes{As soon as I regained my strength, I scheduled an appointment to receive the Covid-19 vaccine. I received the first dose of the vaccine and plan to get the second one after the recommended time between shots.}
\end{quote}
The GPT might extract  \quotes{regaining strength}, \quotes{scheduling appointment for vaccination} and \quotes{receiving first dose of Covid-19 vaccine} as the relevant events. Mentioning the appointment in the event log is superfluous since the text explicitly states that the vaccine was received, which is the relevant information. So, the correct answer is \quotes{regaining strength} and \quotes{receiving first dose of Covid-19 vaccine}, while the rest is omitted.\\
Without knowing that the second sentence is part of the Patient Journey and without understanding the relation between the two sentences, the GPT can not give a correct answer. That is why providing a large context is important for this task.\\
To teach the model which events are relevant and which are not, we also include examples that contain a lot of irrelevant information the model should ignore. In the assistant messages, we can then omit the irrelevant information from the summaries.\\
In addition to full Patient Journeys, short excerpts from Patient Journeys are also viable examples. They fulfil a different purpose. Aside from understanding the situation described in the Patient Journey and isolating the relevant events, we must also train the model on how to output its findings. Providing a multitude of shorter examples creates a blueprint on how actives should be summarized. Active or passive writing style, rephrased or close to the original text and past or present tense are options that should be defined. More on that in the next paragraph.\\\\
Examples that train the model to extract start timestamps contain an activity label representing the event and an excerpt of the original Patient Journey from which the activity label was extracted. This is also the approach chosen in TracEX. The method delicately balances providing the GPT with sufficient context to understand an event's temporal relations against limiting the data volume. This ensures the performance of the GPT is not impaired due to an excess of irrelevant information for the given event~\cite{han_is_2023}.\\\\
Examples for end timestamps work similarly and additionally contain the previously extracted start timestamp. The start timestamp can be an excellent indication for the end timestamp of an event. Providing it makes it easier for the model to understand which event is the current one, thus ensuring that the start and end timestamps refer to the same event. Furthermore, the end timestamp is often not stated at all in the Patient Journey. With knowledge about the start timestamp, the GPT can make better estimations of when the event ended.\\
This way, the fine-tuning examples are structured like the messages the model will be prompted with. Especially concerning timestamps, the input examples need to be diverse. Providing input with different variations of timestamps, as described before, allows us to later provide the model with correct responses to these varying timestamps. This way, the fine-tuned model is more likely to recognize relative specifications like \quotes{during that time} and handle them in a desirable way. \\
User messages for the training of classifying event types are the most straightforward. They consist of just one activity label that should be classified.\\
\autoref{lst:user:starttime} shows what a user message could look like.
\begin{lstlisting}[language=json, caption={User message for determining an activities start timestamp}, label={lst:user:starttime}]
{"role":"user",
 "content":"I started experiencing flu-like symptoms in July 21. I then got tested positive for Covid19. In October, I got infected again. Then on the 4th of November I got my first dosage of the vaccine. I had heavy side effects.\n Activity Label: starting to experience symptoms"
}
\end{lstlisting}

\paragraph{Assistant messages:} An assistant message for activity labelling consists of three to six-word summaries of events from the respective Patient Journey. Our approach is to keep the summaries close to the original text regarding the choice of words. As described in \autoref{sec:tracex}, the created activity label is later on also used to determine the event type and timestamps. To make it easier for the GPT to recognize the activity by its label in the original text, the words should be not too far off. For instance, in ~\autoref{lst:user:starttime} an activity label is used to indicate which of the timestamps present in the context is the relevant one for this request. If that activity had been summarized to \quotes{symtom onset} or \quotes{noticed first symptoms}, the model might have a harder time matching activity and timestamp because the event in question is not recognized.\\
That means the model does not learn to always use a certain structure for the summaries or a specific tense, but to adjust it to the given input instead. The focus of these examples is to provide guidance on which information is important and which is not. A user message that contains only one relevant event and spans five sentences is reduced to just one activity label, representing the one relevant event.\\\\
Assistant messages for classifying event types are just the event type itself from the predefined list. Repeating this output format in every example of the training data teaches the model that no accompanying text is allowed. Otherwise, GPT-5.5 Turbo tends to include phrases like \quotes{Certainly, here is the event type for your activity}. This makes using and evaluating the results much harder, so training the model on the output format is very helpful. \\\\
We apply a similar approach to extracting the time stamps. By defining a format for the timestamps and repeating it in every example, the output is more reliably formatted correctly. The timestamp format required for XES files is \verb|YYYMMDDTHHMM|, so that is what we use.\\
\autoref{lst:assistant:starttime} shows what an assistant message could look like.
\begin{lstlisting}[language=json, caption={Assistant message for determining an activities start timestamp}, label={lst:assistant:starttime}]
{"role":"assistant","content":"20210701T0000"}
\end{lstlisting}

The messages shown in ~\autoref{lst:system:starttime}, \ref{lst:user:starttime} and \ref{lst:assistant:starttime} combine to one element in the training data.\\\\

Fine-tuning, in our case, requires training data that comprises both answerable and non-answerable examples. In particular, it is crucial to provide ample examples where the context supplies sufficient information for the model to deliver an answer and, just as important, examples where the context is insufficient, making it impossible for the model to provide an answer. The ultimate goal of this juxtaposition is to teach the model to effectively differentiate between contexts where an answer can be procured and where it can not.\\
For instance, a lack of specific data, like a timestamp, might result in 'N/A' being the most fitting answer the model can deduce. However, it has been found that GPT-3.5 Turbo often defaults to 'N/A' even when the required information is present. This necessitates that the training data meticulously demonstrates both instances where there genuinely is no answer, separated from situations where the model should  provide an answer. This encourages the model to refrain from utilizing 'N/A' as a response unless it is the only valid option.\\
Furthermore, the training data should strike a balance between simple and complex cases. A sufficient amount of straightforward instances is necessary to cement a clear understanding of rudimentary functioning steps. At the same time, a generous presence of complicated examples is essential to equip the model with the necessary adaptability and problem-solving skills. As mentioned in \ref{par:user-messages} the context from which to extract activity labels can be a complete patient journey, thereby containing multiple examples for mapping sentences to activity labels. This allows us to create simple and complex examples from just one Patient Journey. A set of one to four sentences makes a relatively simple example. Three or four of these sets at once make a much more demanding yet more realistic task. The approach we implement is first to use the simple examples and then follow up with one large example, combining the simpler ones. A shortened example can be seen in~\autoref{lst:combined-example}.
\begin{lstlisting}[language=json, caption={Simple and complex examples for determining activity labels}, label={lst:combined-example}]
{"messages":[
    {"role":"system","content":..."},
    {"role":"user","content":"0: After experiencing the first symptoms of Covid-19 on 2020/09/13, I immediately isolated myself at home to prevent the possible spread of the virus to my family 1: My symptoms started with a mild fever, fatigue, and a dry cough, which progressively worsened over the following days"},
    {"role":"assistant","content":"First symptoms: Mild fever, fatigue, dry cough #0\nIsolated at home #0\nSymptoms worsened #1"}]}
{"messages":[
    {"role":"system","content":"..."},
    {"role":"user","content":"2: By 2020/09/15, I developed difficulty breathing and chest pain, prompting me to consult with a doctor via telemedicine 3: The doctor advised me to monitor my symptoms closely and prescribed medications to alleviate fever and cough."},
    {"role":"assistant","content":"Developed difficulty breathing, chest pain #2\nConsulted doctor via telemedicine #2\nDoctor prescribed medications #3"}]}
{"messages":[
    {"role":"system","content":"..."},
    {"role":"user","content":"0: After experiencing the first symptoms of Covid-19 on 2020/09/13, I immediately isolated myself at home to prevent the possible spread of the virus to my family 1: My symptoms started with a mild fever, fatigue, and a dry cough, which progressively worsened over the following days 2: By 2020/09/15, I developed difficulty breathing and chest pain, prompting me to consult with a doctor via telemedicine 3: The doctor advised me to monitor my symptoms closely and prescribed medications to alleviate fever and cough"},
    {"role":"assistant","content":"First symptoms: Mild fever, fatigue, dry cough #0\nIsolated at home #0\nSymptoms worsened #1\nDeveloped difficulty breathing, chest pain #2\nConsulted doctor via telemedicine #2\nDoctor prescribed medications #3"}]}
\end{lstlisting}

\subsubsection{Data Sources}\label{sec:data_sources}
This chapter outlines how we acquire and prepare the data we use to fine-tune the model. In the process of acquiring training data for fine-tuning, three main steps are employed:\\\\
Firstly, sample data that can serve as input is collected. This includes gathering real-world patient journeys and potentially making minor adjustments to ensure their utility as examples. We need to ensure that the training data features input that the base model struggles with in order to demonstrate how the fine-tuned model should handle those cases. Additionally, we generate synthetic patient journeys because of their clear structure and completeness. Hence, they are well-suited for serving as basic training examples for the core aspects of extraction and validation.\\\\
Secondly, we use the TracEX pipeline to establish a starting point for ground truths. This process entails incorporating few-shot prompts from TracEX into the training data, as these are already excellent examples. Then, we execute the pipeline using the collected Patient Journeys and log the intermediate results of the pipeline in a suitable JSON format that is compatible with use as training data. Each step we intend to fine-tune the model for is represented in the intermediate results. For instance, we copy the system and user message in TracEX's query to the ChatGPT API and use the API's response as the assistant message. This way, each execution of the pipeline produces one set of messages that can be used as training data. However, manual checking and corrections are absolutely necessary at this stage, as errors occur, compromising the training examples. It is crucial that the training samples are free from fault. Otherwise, this could propagate the faults into the fine-tuned model. Naturally, these intermediate results are merely a starting point. If TracEX could already extract the required information so well that it could be used as fine-tuning training data, fine-tuning would not be required at all.\\\\
Lastly, we request GPT-4 to do the same extraction tasks as TracEX, and also use the results as examples in the training data. ChatGPT 4 outputs outperform those from GPT-3.5 Turbo and exemplify what the fine-tuned model should achieve after fine-tuning. Nonetheless, the results still need further human refining and adjustments. To curtail costs, we use the batch-upload feature from OpenAI to make many of the required requests to the API since it is cheaper.

\subsubsection{Parameters}
OpenAI provides three key hyperparameters that allow for customization of the fine-tuning process~\footnote{\href{https://platform.openai.com/docs/api-reference/fine-tuning/create\#fine-tuning-create-hyperparameters}{OpenAI API documentation}}: epochs, batch size, and learning rate multiplier. Epoch refers to one complete pass through the entire training dataset. Increasing it makes the model's answers comply more closely with the training data. This can also lead to overfitting, which is especially harmful for tasks that allow more varied answers. Since our set of tasks involves such tasks but also ones that require very specific answers, we opt to use two epochs. The batch size parameter determines the number of training examples used in one iteration to update the model’s parameters. Given our relatively small dataset of around 100 examples across four tasks, we choose a batch size of one to maximize the utility of each training example. It is worth noting that these 100 examples amount to about 32000 tokens or 24000 words. The learning rate multiplier adjusts the base learning rate, which controls how much the model’s weights are updated concerning the calculated error after each epoch. Due to the limited training data, we choose a learning rate multiplier of 2 to enable the model to learn more quickly. 

\subsection{Single-task fine-tuning}\label{sec:single-task-ft}
In this chapter, we will describe the process of task-specific fine-tuning for one task. For this purpose, we choose to train a model for extracting activity labels from Patient Journeys. This task is one of the most difficult among the tasks we have introduced so far and is also a more interesting subject than a traditional classification task, such as the one done in the event type classification step.\\
Extracting activity labels for events in Patient Journeys is a complex task. It requires an understanding of the condition at hand because it also implies determining which of the mentioned activities are relevant to the case. Fine-tuning an LLM for a single task allows us to focus on more of the issues a model has with performing the task. By providing even more examples in the form of training data, we intend to teach the model how to handle difficult tasks without diverging the attention of the model by introducing other tasks, as we did in \autoref{sec:multi-task-ft}. This makes it a valuable approach.\\\\
Curating datasets is, and the data sources for this model are very similar to the process described in \autoref{sec:data_sources} and \autoref{sec:curating_data} respectively. All approaches described for collecting examples for the task of labelling activities apply to the training of the single-task fine-tuned model as well. The sole difference is that \emph{all} examples we train the model with are specific to labelling activities.\\\\
The training data for this model contains 50 examples for the task "Activity Labelling". This is double the amount the multi-task fine-tuned model got, which amounts to approximately 16000 tokens. Because this set of training data is more specialized but still smaller overall, we choose to adjust the Hyperparameters: 3 Epochs, Batch Size 1, and LR-Multiplier 2.

\subsection*{Summary}
Fine-tuning a GPT model for information extraction tasks starts with collecting or generating sample data from which to extract the information. Next, ground-truths for individual texts need to be created to create examples from which the model can learn. The examples need to be manually validated and adjusted to ensure they are free from any faults that would otherwise harm the model's performance. Suitable hyperparameters need to be chosen depending on the kind of task-mix the model should perform and the number of total examples in the training data. The training data needs to address the base model's problems by providing examples and possible answers so the model can learn how to handle the problematic cases. High quality and a high quantity of training data are crucial.\\
The complete fine-tuning data can be checked \href{https://github.com/FR-SON/Bachelor-Thesis}{here}.