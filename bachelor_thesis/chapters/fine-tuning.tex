\section{Fine-Tuning Strategies}\label{sec:fine}
In the following chapters, we will present an approach to fine-tuning ChatGPT 3.5 turbo, that is specialized for the task of extracting event logs from patient journeys. We will use four of the steps used in TracEX to demonstrate: Extracting activity labels, classifying event types, extracting start timestamps and extracting end timestamps. Part of that approach is preparing the datasets for training and validating the model. This is mainly due to the fact, that the desired application is a niche subject which results in a lack of large, established datasets. Curating and assembling the training data is a time-consuming yet crucial task in fine-tuning an LLM.\\\\
Since we use ChatGPT and the corresponding tools from OpenAI, the set of applicable fine-tuning strategies is limited. As mentioned in \ref{sec:fine-tuning-def} there are fundamentally 3 different strategies, that are potentially interesting: Supervised fine-tuning (SFT), unsupervised fine-tuning and reinforcement learning. The fine-tuning framework OpenAI provides is focused on SFT, so that is what we focus on as well. Fittingly, SFT is said to be suited for improving a model's understanding of complex tasks and increasing the reliability of correctly formatted responses, which is the purpose we use fine-tuning for.\\
Another dimension in which one can differentiate fine-tuning strategies is the number of tasks a model is fine-tuned for.\\
\emph{Multi-task fine-tuning} means training a model on multiple related tasks at the same time – within one dataset. By leveraging the commonalities of the tasks, the model can learn and understand quicker, decreasing the number of examples it needs to increase its performance in all the tasks.\\
\emph{Task-specific fine-tuning} on the other hand means training a model for only one well-defined, isolated task. This enables an even more refined understanding of the intricate details of one specific task. Especially with very complex tasks or those that require a deeper understanding of the domain, this method excels.\\\\
The individual steps included in the extraction framework of TracEX can be categorized into different types of tasks. Each type poses different challenges and has a different complexity. The classification of event types requires the GPT to select the correct answer from a predefined set of choices. On top of that, the given context is relatively small. (Example) Determining the relevant activities is a much more complex task and the GPTs response is only limited by the number of words that should represent one activity. The exact words that make up the activity is up to the GPT to decide. The context for that task is larger as well, since all sentences have to be examined in context in order to determine which activities are relevant and which descriptions make up one event in the patient journey. Deriving timestamps for activities is without a doubt the hardest task. Not only is temporal information often hardly present or missing all together in real-world patient journeys, but can also take many shapes. 'On 2024/04/02', 'at the beginning of August', 'On Tuesday', 'In autumn', 'As the week progressed', 'Later' are all examples from real-world patient journeys, that need to be converted into XES-conform timestamps. So, adding to all the challenges involved in this type of task, is the requirement for correct formatting.

\subsection{Multi-task fine-tuning}\label{sec:multi-task-ft}
In this chapter we will describe the process of multi-task fine-tuning ChatGPT 3.5 turbo for all the mentioned tasks – labelling activities, classifying event types,  determining start timestamps and determining end-timestamps. This strategy counteracts the fact, that the size of the datasets will always be relatively small, compared to the datasets used in the work presented in chapter~\ref{related_work}. Examples that explain the classification of event types for instance, take activity labels as input, which means this step also profits from the examples for extracting activity labels, because more possible activity labels are presented throughout the training process. The underlying task in all steps is to understand, extract and transform information from a text. This makes it a valuable approach.

\subsubsection{Curating Datasets}\label{sec:curating_data}
\paragraph{System Messages:} The system-message is in most cases identical to the system prompt used in TracEX – for two reasons:
\begin{enumerate}
    \item
        The prompts are complex, specifying the thought process the model should take, the format of the response and which aspects of the input to focus on. Showing the model how to respond to these specific instructions underlines the connection between the details of the instructions and the desired output. For example, if the instruction includes \quotes{Answer, using only one word.} and the assistant-message contains only one word, it should be easier for the model to understand how to action this instruction in the future. Thus, the training data prepares the model for the exact instructions it will be prompted with.\\
        The drawback of this approach is, that the prompts used with the fine-tuned model can not be shortened as much. They still need to contain every specification that is necessary for the base model. On the other hand, this makes the model more flexible: If a prompt contains special instructions, they will be implemented. If a prompt does not contain special instructions, no predefined formatting or similar customizations will pre present in the response.\\
        Teaching a model to behave in a certain way purely by examples – omitting the explanations in the system messages, but keeping the output the same – can also work. But because the fine-tuned model has no connections between the instructions and the demanded behaviour, it will always behave like the examples taught it to, making it less flexible. That is why we did not choose this approach.
    \item 
        Showing the model the exact same instruction over and over again, should result in the model being primed to fulfil that task, without being 'distracted' by other possible instructions. It knows only this one task, to exaggerate. Of course, a pre-trained model like ChatGPT 3.5 turbo has vast knowledge about various other tasks. Fine-tuning only changes the model on the surface level. Still, this should be considered, which is why we propose the approach of keeping the system prompts close to ones that will actually be used with the fine-tuned model.
\end{enumerate}

\begin{lstlisting}[language=json, caption={System message for determining an activies start timestamp}, label={lst:system:starttime}]
{"role":"system",
 "content":"You are an expert in text understanding and your job is to take a given text and a given activity label and to extract a start date to this activity label. Only output the extracted start date! Rely on the context to determine the start date, as it might not be explicitly mentioned."
}
\end{lstlisting}

\paragraph{User messages:}\label{par:user-messages} Sample tasks in the user-messages should also be similar to the ones the fine-tuned model will face in reality. The training data contains example inputs like they are described in chapter\ref{sec:back}:\\
Training data for the activity labelling step is an entire patient journey. The goal is to convey which parts of the huge context are important. In order to demonstrate which aspects to keep and which to discard in the assistant-message, the entire journey is necessary.\\
To illustrate, assume a patient journey contains the following paragraph:
\begin{quote}
    \quotes{As soon as I regained my strength, I scheduled an appointment to receive the Covid-19 vaccine. I received the first dose of the vaccine and plan to get the second one after the recommended time between shots.}
\end{quote}
The GPT might extract \quotes{scheduling appointment for Vaccination} and \quotes{receiving first dose of Covid-19 vaccine} as the relevant events. Mentioning the appointment in the event log is superfluous, since the text states explicitly, that the vaccine was received and that is the relevant information. So, the correct answer should be \quotes{receiving first dose of Covid-19 vaccine}, while the rest is omitted.\\
Without knowing, that the second sentence is part of the patient journey and without understanding the relation between them, the GPT can not give a correct answer. That is why providing a large context is important for this task.\\
However, excerpts from patient journeys, four sentences or shorter, are also viable. They fulfil a different purpose. Aside from understanding the situation described in the patient journey and isolating the relevant events, the model also needs to be trained on how to output its findings. Providing a multitude of shorter examples, creates a blueprint on how actives should be summarized. Active or passive writing style, rephrased or close to the original text, past or present tense are options that should be defined, more on that in the next paragraph.\\\\
Examples that train for the extraction of start timestamps contain an activity label, representing the event, and an excerpt of the original patient journey which the activity label was extracted from before. This is also the approach chosen in TracEX. The method delicately balances providing the GPT with sufficient context to understand the temporal relations of an event against limiting the volume of data. This ensures the performance of the GPT is not impaired due to an excess of irrelevant information for the given event~\cite{han_is_2023}.\\
Examples for end timestamps work similarly, additionally containing the previously extracted start timestamp. The start timestamp can be a great indication for the end timestamp of an event. Providing it ensures, the model relies on that timestamp instead of determining it itself.
In this way, the fine-tuning examples are structured just like the messages, the model will be prompted with. Especially concerning timestamps, the input examples need to be diverse. By providing input with different variations of timestamps as described before allows us to later on provide the model with  correct responses to these varying timestamps. This way, the fine-tuned model is more likely to recognize relative specifications like 'during that time' and handle them in a desirable way. \\
User messages for the training of classifying event types are the most straight forward. They consist of just one activity label, that should be classified.
\begin{lstlisting}[language=json, caption={User message for determining an activities start timestamp}, label={lst:user:starttime}]
{"role":"user",
 "content":"I started experiencing flu-like symptoms in July 21. I then got tested positive for Covid19. In October I got infected again. Then on the 4th of November I got my first dosage of the vaccine. I had heavy side effects.\n Activity Label: starting to experience symptoms"
}
\end{lstlisting}

\paragraph{Assistant messages:} An assistant message for activity labelling consists of 3-6 word summaries of events from the respective patient journey. The approach we follow is to keep the summaries close to the original text, regarding the choice of words. As described in chapter~\ref{sec:back}, the created activity label is later on also used to determine the event type and timestamps. To make it easier for the GPT to recognize the activity by its label in the original text, the words should be not too far off. For instance, in listing~\ref{lst:user:starttime} an activity label is used to indicate which of the timestamps present in the context is the relevant one for this request. If that activity had been summarized to \quotes{symtom onset} or \quotes{noticed first symptoms} the model might have a harder time matching activity and timestamp, because the event in question is not recognized.\\
That means the model does not learn to always use a certain structure for the summaries or a specific tense, but to adjust it to the given input instead. The focus of these examples is to provide guidance on which information is important and which is not.\\
Assistant messages for classifying event types are just the event type itself, from the predefined list. Repeating this output format in every example of the training data teaches the model, that no accompanying text is allowed. Otherwise, ChatGPT tends to include phrases like \quotes{Certainly, here is the event type for your activity}. This makes using and also evaluating the results much harder, so training the model on the output format is very helpful. \\
A similar approach is applied for the time stamps. By defining a format for the timestamps and repeating it in every example, the output is formatted correctly a lot more reliably. The timestamp format required for XES files is \verb|YYYMMDDTHHMM|, so that is what we use.
\begin{lstlisting}[language=json, caption={Assistant message for determining an acitivities start timestamp}, label={lst:assistant:starttime}]
{"role":"assistant","content":"20210701T0000"}
\end{lstlisting}

The messages shown in listing~\ref{lst:system:starttime}, \ref{lst:user:starttime}, \ref{lst:assistant:starttime} combine to one element in the training data.\\

Fine-tuning in our case requires training data that comprises both answerable and non-answerable examples. In particular, it is crucial to provide ample examples where the context supplies sufficient information for the model to deliver an answer, and just as important, examples where the context is insufficient, making it impossible for the model to provide an answer. The ultimate goal of this juxtaposition is to teach the model to effectively differentiate between contexts where an answer can be procured and where it can not.\\
For instance, a lack of specific data, like a timestamp, might result in 'N/A' being the most fitting option the model can deduce. However, it has been found that ChatGPT 3.5 turbo often defaults to 'N/A' even when the required information is present. This necessitates that the training data meticulously demonstrates both instances where there genuinely is no answer, separated from situations where an answer should indeed be provided. This encourages the model to refrain from utilizing 'N/A' as a response unless it’s genuinely the only valid option left.\\
Furthermore, the training data should strike a balance between simple and complex cases. A sufficient amount of straightforward instances is necessary to cement a clear understanding of rudimentary functioning steps. At the same time, a generous presence of complicated examples is essential to equip the model with the necessary adaptability and problem-solving skills. As mentioned in \ref{par:user-messages} the context from which to extract activity labels can be a complete patient journey, thereby containing multiple examples for the mapping of sentences to activity labels.  This allows us to create simple and complex examples from just one patient journey. A set of one to four sentences makes a rather simple example. Three or four of these sets at once make a much harder, yet more realistic, task. The approach we implement is to first use the simple examples and follow up with one large example, combining the simpler ones. You can see a shortened example of that in~\autoref{lst:combined-example}.
\begin{lstlisting}[language=json, caption={Simple and complex examples for determining acitivity labels}, label={lst:combined-example}]
{"messages":[
    {"role":"system","content":..."},
    {"role":"user","content":"0: After experiencing the first symptoms of Covid-19 on 2020/09/13, I immediately isolated myself at home to prevent the possible spread of the virus to my family 1: My symptoms started with a mild fever, fatigue, and a dry cough, which progressively worsened over the following days"},
    {"role":"assistant","content":"First symptoms: Mild fever, fatigue, dry cough #0\nIsolated at home #0\nSymptoms worsened #1"}]}
{"messages":[
    {"role":"system","content":"..."},
    {"role":"user","content":"2: By 2020/09/15, I developed difficulty breathing and chest pain, prompting me to consult with a doctor via telemedicine 3: The doctor advised me to monitor my symptoms closely and prescribed medications to alleviate fever and cough."},
    {"role":"assistant","content":"Developed difficulty breathing, chest pain #2\nConsulted doctor via telemedicine #2\nDoctor prescribed medications #3"}]}
{"messages":[
    {"role":"system","content":"..."},
    {"role":"user","content":"0: After experiencing the first symptoms of Covid-19 on 2020/09/13, I immediately isolated myself at home to prevent the possible spread of the virus to my family 1: My symptoms started with a mild fever, fatigue, and a dry cough, which progressively worsened over the following days 2: By 2020/09/15, I developed difficulty breathing and chest pain, prompting me to consult with a doctor via telemedicine 3: The doctor advised me to monitor my symptoms closely and prescribed medications to alleviate fever and cough"},
    {"role":"assistant","content":"First symptoms: Mild fever, fatigue, dry cough #0\nIsolated at home #0\nSymptoms worsened #1\nDeveloped difficulty breathing, chest pain #2\nConsulted doctor via telemedicine #2\nDoctor prescribed medications #3"}]}
\end{lstlisting}

\subsubsection{Data Sources}\label{sec:data_sources}
In the process of acquiring training data for fine-tuning, three main steps are employed:\\\\
Firstly, sample data that can serve as input is collected. This includes gathering real-world patient journeys and potentially making minor adjustments to ensure their utility as examples. Additionally, synthetic patient journeys are generated, because of their clear structure and completeness. Hence, they are well-suited for serving as basic training examples for the core aspects of extraction and also for validation.\\\\
Secondly, the TraceEx pipeline is utilized to establish a starting point. This process entails incorporating few-shot prompts from TracEX into the training data, as these are already excellent examples. The pipeline is then executed using the collected patient journeys and the intermediate results of the pipeline are logged in a suitable JSON format compatible with use as training data. Each step we intend to fine-tune the model for is represented in the intermediate results. For instance, in the extraction of start dates, the system message utilized in TracEX' query to the ChatGPT API is copied. The user message is taken from the request made to the API, and the API's response is used as the assistant message. This way, each execution of the pipeline produces a set of messages, that can be used as training data. However, manual checking and corrections are absolutely necessary at this stage, as errors occur, thereby compromising the training examples. It is crucial that the training samples are free from fault, otherwise, this could propagate the faults into the fine-tuned model.\\\\
Lastly, ChatGPT 4 is requested to do the same extraction tasks as TracEX and the results are used as examples in the training data as well. ChatGPT 4 outputs outperform those from ChatGPT 3.5 turbo and exemplify what the fine-tuned model should achieve after fine-tuning. Nonetheless, the results still need further human refining and adjustments. In order to curtail costs, the batch-upload feature from OpenAI is used to make many of the required requests to the API, as it is 50\% cheaper.

\subsubsection{Parameters}
OpenAI provides three key hyperparameters that allow for customization of the fine-tuning process: epochs, batch size, and learning rate multiplier. Epoch refers to one complete pass through the entire training dataset. Increasing it makes the models answers comply more closely to the training data. This can also lead to overfitting, which is especially harmful for tasks that allow more varied answers. Since our set of tasks involves such tasks but also ones that require very specific answers, we opt to use two epochs. The batch size parameter determines the number of training examples used in one iteration to update the model’s parameters. Given our relatively small dataset of around 100 examples across four tasks, we chose a batch size of one to maximize the utility of each training example. It is worth noting, that these 100 examples amount to about 32000 tokens or 24000 words. The learning rate multiplier adjusts the base learning rate, which controls how much the model’s weights are updated with respect to the calculated error after each epoch. Due to the limited training data, we opted for a learning rate multiplier of 2 to enable the model to learn more quickly. 

\subsection{Single-task fine-tuning}\label{sec:single-task-ft}
In this chapter, we will describe the process of task-specific fine-tuning for one task, that still poses a significant challenge to the multi-task fine-tuned model. For this purpose, we choose to train a model for extracting activity labels from a Patient Journey. This task is one of the most difficult among the repertoire of TracEX and is also a more interesting subject than a traditional classification task, such as done in the event type classification step.~\ref{sec:tracex}\\
Extracting activity labels for events in Patient Journeys is a complex task. It requires an understanding of the condition in hand, because it also implies determining which of the mentioned activities is relevant for the case. Fine-tuning a LLM for a single task allows us to focus on more of the issues a model has with performing the task. By providing even more examples in the form of training data, we intend to teach the model how to handle difficult tasks, without diverging the attention of the model by introducing other tasks, like we did in \autoref{sec:multi-task-ft}. This makes it a valuable approach.\\\\
Curating datasets is and the data sources for this model are very similar to the process described in \autoref{sec:data_sources} and \autoref{sec:curating_data} respectively. All approaches described for collecting examples for the task of labelling activities applies to the training of the single-task fine-tuned model as well. The sole difference is, that \emph{all} examples we train the model with are specific to labelling activities.\\\\
The training data for this model contains 50 examples for the task "Activity Labelling". This is double the amount the multi-task fine-tuned model got. This amounts to approximately 16000 tokens. Because this set of training data is more specialized but still smaller overall we choose to adjust the Hyperparameters: 3 Epochs, Batch Size 1 and LR-Multiplier 2.

\subsection*{Summary}
The process of fine-tuning a ChatGPT model for information extraction tasks starts with collecting or generating sample data from which to extract the information. Next, ground-truths for individual texts need to be created in order to create examples the model can learn from. The examples need to be manually validated and adjusted to ensure they are free from any faults, that would otherwise harm the model's performance. Depending on the kind of task-mix the model should later on perform and number of total examples in the training data, suitable hyperparameters need to be chosen. The training data needs to address the problems the base model has, by providing examples and possible answers, so the model can learn how to handle the problematic cases. High quality as well as high quantity of the training data is crucial.
