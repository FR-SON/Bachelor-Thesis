\section{Discussion}\label{sec:discussion}
In this chapter, we will discuss the approaches and the results we achieved in hindsight.\\\\
Both approaches to fine-tuning improved GPT5.5 Turbo's performance. In some metrics, there are noticeably fewer improvements.\\
\begin{itemize}
    \item To our surprise, fine-tuning did not improve the model's capabilities in classifying event types for activities. This is the easiest of the four tasks we evaluated, and the base model performed reasonably well. The reason for that is likely a lack of diversity in the training data. In many Patient Journeys, events of type System Onset are more common than Treatment or Medication because patients can describe how they felt and experienced in more detail, compared to treatment and medication plans. Our training data reflects that.
    \item The single-task fine-tuned model performed worse or on par with the multi-task fine-tuned model in their mutual task. This is not necessarily an issue. The model learns from all the examples we provide during training and will what it learned in every response. Consequently, the examples intended to train the model for Event Type Classification can also improve its performance in Activity Labelling. Even though the single-task fine-tuned model received twice as many examples for the task \quotes{Activity Labelling} than the multi-task fine-tuned model, the overall number of examples was lower. The conclusion is that multi-task fine-tuning, in this case, is the superior approach. More training data could tip the scale, however.
\end{itemize}
The focus of \autoref{sec:fine} is selecting the correct training data and assembling data sets that the model can benefit from the most. We discussed various approaches and reasoned why one is better than the other. This relies on our experimentation, previous research, and claims made by OpenAI. Ultimately, all models we used are black-boxes, and there is no way to comprehend how exactly GPT-35.5 Turbo digested the data we provided.