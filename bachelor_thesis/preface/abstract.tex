\begin{abstract}
Extracting event logs from natural language text is a discipline that gets more and more attention in academic circles, particularly with the advancement of large language models (LLMs) in the past years. On top of the challenges that exist when applying process mining on event logs extracted from traditional sources, additional hindrances arise with event logs based on natural language text. In order to address the challenges that the lack of structure and significant variance in natural language text pose in the extraction of information, fine-tuning LLMs for specific domains was researched in various fields of study. This thesis presents different approaches to fine-tuning a pre-trained model for extracting event logs from Patient Journeys. We thereby document the efficacy of established strategies for this use case. We focus on curating optimal training data sets and include details on the training process. Specifically, we apply supervised fine-tuning on GPT-3.5 Turbo with multi-task and single-task fine-tuning approaches. Our findings demonstrate promise, especially with multi-task fine-tuning, where the efficacy of fine-tuning is particularly pronounced. By evaluating the extraction on five metrics across four tasks, we present the fine-tuned model as superior in three of the evaluated tasks.
This research underscores the potential of fine-tuning LLMs to improve event log extraction from unstructured text, thereby enhancing process mining outcomes.
\end{abstract}
\clearpage
\begin{abstract}
Ereignissprotokolle aus natürlichsprachigem Text zu extrahieren ist eine Herausforderung, die in akademischen Kreisen im Laufe der letzen Jahre zunehmend Aufmerksamkeit bekommt, insbesondere durch die Weiterentwicklung von large langueage models (LLMs). Zusätzlich zu den Herausforderungen die beim Anwenden von Process Mining Techniken auf Ereignisprotokolle aus traditionellen Quellen entstehen, gibt es noch weitere Hindernisse wenn natürlichsprachlicher Text als Quelle verwendet wird. Fine-Tuning wurde bereits in einigen Forschungsbereichen eingesetzt, um die Probleme anzugehen die durch die mangelnde Struktur und die signifikante Varianz von natürlichsprachigem Text entstehen. Diese Arbeit zeigt verschiedene Ansätze, um ein vortrainiertes Modell für die Aufgabe Ereignisprotokolle aus Patient Journeys zu extrahieren, zu fine-tunen. Wir dokumentieren dabei die Wirksamkeit etablierter Strategien für diesen Anwendungsfall. Den Fokus legen wir dabei auf die Zusammenstellung optimaler Trainingsdaten und gehen detailliert auf den Trainingsprozess ein. Konkret wenden wir Supervised Fine-Tuning auf GPT-3.5 Turbo an und verwenden dabei multi-task und single-task Ansätze an. Unsere Ergbnisse sind vielversprechend, insbesondere unter Verwendung des multi-task Ansatzes. Durch Evaluierung von vier Schritten der Extraktion mit Hilfe von fünf Metriken zeigen wir die Überlegenheit des fine-tuned Modells in drei der vier Aufgaben.
Diese Arbeit verdeutlicht das Potenzial von Fine-Tuning, um die Extraktion von Ereignisprotokollen aus unstrukturiertem Text zu optimieren und dadurch die Qualität von Process Minings zu steigern.
\end{abstract}