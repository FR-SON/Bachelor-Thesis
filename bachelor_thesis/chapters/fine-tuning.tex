\section{Fine-Tuning Strategies for Event Log Extraction}\label{sec:fine}
In the following chapters, we present approaches to fine-tuning GPT-3.5 Turbo, tailored specifically for the extraction of event logs from Patient Journeys. We use four of the steps used in TracEX to demonstrate: Extracting activity labels, classifying event types, extracting start timestamps and extracting end timestamps. One integral aspect of these approaches is preparing the datasets for training and validating the model. This is mainly because the desired application is a niche subject, resulting in a lack of large, established datasets. Curating and assembling the training data is a time-consuming yet crucial task in fine-tuning an LLM.\\\\
Since we use GPT-3.5 Turbo and the corresponding tools from OpenAI, the set of applicable fine-tuning strategies is limited. As mentioned in \autoref{sec:fine-tuning-def}, there are fundamentally three potentially interesting strategies: Supervised fine-tuning (SFT), unsupervised fine-tuning and reinforcement learning. OpenAI's fine-tuning framework is centred around SFT, so we concentrate on that as well. SFT is known for enhancing a model's understanding of complex tasks and increasing the reliability of correctly formatted responses, which aligns with our use of fine-tuning.\\
Please also note the difference between \emph{multi-task fine-tuning} and \emph{task-specific fine-tuning}. The terms refer to the number of tasks a fine-tuned model should perform. Both approaches have advantages and disadvantages, which we introduce in \autoref{sec:fine-tuning-def}.\\
The individual steps included in the extraction framework of TracEX differ in the autonomy granted to the model and the scope of context taken into consideration. Each task presents distinct challenges and complexity levels.
Classifying event types requires the GPT to select the correct answer from a predefined set of choices. Determining the relevant activities is a much more complex task, and the GPT's response is only limited by the number of words that should represent one activity. Deriving timestamps for activities is, without a doubt, the most challenging task. Not only is temporal information often hardly present or missing altogether in real-world Patient Journeys, but it can also take many shapes. \quotes{On 2024/04/02}, \quotes{at the beginning of August}, \quotes{On Tuesday}, \quotes{In autumn}, \quotes{As the week progressed}, and \quotes{Later} are all examples from real-world Patient Journeys that need to be converted into XES-conform timestamps. The derived timestamps must adhere to the specified format; beyond that, the model's output cannot be further restricted, and the model must discern the correct one from all possible ones.\\
Classifying event types relies on a relatively small context consisting of just the activity to be classified, determining relevant activities requires a large context as all sentences in the Patient Journey must be examined, and deriving timestamps necessitates a medium context spanning a few sentences before and after the currently examined activity.

% Classifying event types requires the GPT to select the correct answer from a predefined set of choices. On top of that, the given context is relatively small. Determining the relevant activities is a much more complex task, and the GPT's response is only limited by the number of words that should represent one activity. The exact words that make up the activity are up to the GPT to decide. The context for that task is larger as well since all sentences have to be examined in the context in order to determine which activities are relevant and which descriptions make up one event in the Patient Journey. Deriving timestamps for activities is, without a doubt, the most challenging task. Not only is temporal information often hardly present or missing altogether in real-world Patient Journeys, but it can also take many shapes. \quotes{On 2024/04/02}, \quotes{at the beginning of August}, \quotes{On Tuesday}, \quotes{In autumn}, \quotes{As the week progressed}, and \quotes{Later} are all examples from real-world Patient Journeys that need to be converted into XES-conform timestamps. So, adding to all the challenges involved in this type of task is the requirement for correct formatting.

\subsection{Multi-Task Fine-Tuning}\label{sec:multi-task-ft}
In this chapter, we describe the process of multi-task fine-tuning GPT-3.5 Turbo for all the mentioned tasks – labelling activities, classifying event types,  determining start timestamps and determining end timestamps. This strategy counteracts the fact that the size of the dataset is relatively small compared to the datasets used in the work presented in ~\autoref{sec:related_work}. Examples that explain the classification of event types, for instance, take activity labels as input, which means this step also profits from the examples for extracting activity labels because we present more possible activity labels throughout the training process. The underlying task in all four steps is to understand, extract and transform information from a text. This similarity in the tasks makes training them together a valuable approach.

\subsubsection{Curating Datasets}\label{sec:curating_data}
We structure this chapter into three paragraphs. Each paragraph describes one of the message types we need in our fine-tuning training data, starting with system messages, then user messages, and finally, assistant messages. Furthermore, each paragraph sequentially describes the characteristics of the different messages for activity labelling, start and end timestamp extraction, and event type classification.
\paragraph{System Messages:} The system message is, in most cases, identical to the system prompt used in TracEX – for two reasons:
\begin{enumerate}
    \item
        The prompts are complex, specifying the thought process the model should take, the response format, and the aspects of the input to focus on. Showing the model how to respond to these specific instructions underlines the connection between the details of the instructions and the desired output. For example, suppose the instruction includes \quotes{Answer, using only one word.} and the assistant message contains only one word. In that case, it is easier for the model to understand how to action this instruction in the future. Thus, the training data prepares the model for the exact instructions we will prompt it with.\\
        The drawback of this approach is that we can not shorten the prompts used with the fine-tuned model as much. Usually, a fine-tuned model can handle prompts with less detailed descriptions, compared to non-fine-tuned models. In our case, the system messages still need to contain every specification that is necessary for the base model. On the other hand, this makes the model more flexible: If a prompt contains special instructions, the model will implement them. If a prompt does not contain special instructions, no predefined formatting or similar customizations will be present in the response.\\
        Teaching a model to behave in a certain way purely by examples – omitting the explanations in the system messages but keeping the output the same – can also work. However, because the fine-tuned model has no connections between the instructions and the behaviour demanded in the examples, it will always behave like the examples taught it to, making it less flexible. That is why we do not choose this approach.
    \item 
        Showing the model the exact same instruction repeatedly results in the model being primed to fulfil that task without being \quotes{distracted} by other possible instructions. It knows only this one task, to exaggerate. Of course, a pre-trained model like GPT-3.5 Turbo has vast knowledge about various other tasks. Fine-tuning only changes the model on the surface level. Still, we need to consider this, which is why we propose keeping the system prompts close to the ones that will be used with the fine-tuned model.
\end{enumerate}
\autoref{lst:system:starttime} shows what a system message can look like.

\begin{lstlisting}[language=json, caption={System message for determining an activities start timestamp}, label={lst:system:starttime}, float=ht]
{"role":"system",
 "content":"You are an expert in text understanding and your task is to take a given text and a given activity label  and to extract a start date to this activity label. Only output the extracted start date! Rely on the context to determine the start date, as it might not be explicitly mentioned."
}
\end{lstlisting}

\paragraph{User Messages:}\label{par:user-messages} Sample inputs in the user-messages should also be similar to the ones the fine-tuned model will encounter in reality. The training data contains example inputs like they are described in \autoref{sec:tracex}:\\
Training data for the activity labelling step is an entire Patient Journey. The goal is to convey which parts of the huge context are important. In order to demonstrate which aspects to keep and which to discard in the assistant-message, the entire journey is necessary.\\
To illustrate, assume a Patient Journey contains the following paragraph:
\begin{quote}
    \quotes{As soon as I regained my strength, I scheduled an appointment to receive the Covid-19 vaccine. I received the first dose of the vaccine and plan to get the second one after the recommended time between shots.}
\end{quote}
The GPT might extract \quotes{regaining strength}, \quotes{scheduling appointment for vaccination} and \quotes{receiving first dose of Covid-19 vaccine} as the relevant events. Mentioning the appointment in the event log is superfluous since the text explicitly states that the vaccine was received, which is the relevant information. So, the correct answer is \quotes{regaining strength} and \quotes{receiving first dose of Covid-19 vaccine}, while the rest is omitted.\\
Without knowing that the second sentence is part of the Patient Journey and without understanding the relation between the two sentences, the GPT can not give a correct answer. That is why providing a large context is important for this task.\\
To teach the model which events are relevant and which are not, we also include examples that contain much irrelevant information the model should ignore. In the assistant messages, we can then omit the irrelevant information from the summaries, demonstrating the consideration the model should make.\\
In addition to full Patient Journeys, short excerpts from Patient Journeys are also viable examples. They fulfil a different purpose. Alongside comprehending the scenario depicted in the Patient Journey and isolating pertinent events, we must also train the model on how to output its findings. Providing numerous concise examples establishes a framework for the summarization process, encompassing considerations such as active or passive writing style, paraphrasing, and tense selection. More on that in the next paragraph.\\\\
Examples that train the model to extract start timestamps contain an activity label representing the event and an excerpt of the original Patient Journey from which the activity label was extracted. This is also the approach chosen in TracEX. The method delicately balances providing the GPT with sufficient context to understand an event's temporal relations against limiting the data volume. This ensures the performance of the GPT is not impaired due to an excess of irrelevant information for the given event~\cite{han_is_2023}.\\\\
Examples for end timestamps work similarly and additionally contain the previously extracted start timestamp. The start timestamp can be an excellent indication for the end timestamp of an event. Providing it makes it easier for the model to understand which event is the currently observed one, thus ensuring that the start and end timestamps refer to the same event. Furthermore, the end timestamp is often not stated at all in the Patient Journey. With knowledge about the start timestamp, the GPT can make better estimations of when the event ended. Our user messages feature examples that help us demonstrate the correct handling of various possible time specifications in the assistant messages.\\
This way, the fine-tuning examples are structured like the messages the model will be prompted with. Especially concerning timestamps, the input examples need to be diverse. Providing input with different variations of timestamps allows us to later provide the model with correct responses to these varying timestamps. This way, the fine-tuned model is more likely to recognize relative specifications like \quotes{during that time} and handle them in a desirable way. \\\\
User messages for the training of classifying event types are the most straightforward. They consist of just one activity label that should be classified.\\
\autoref{lst:user:starttime} shows what a user message could look like.
\begin{lstlisting}[language=json, caption={User message for determining an activities start timestamp}, label={lst:user:starttime}, float=ht]
{"role":"user",
 "content":"I started experiencing flu-like symptoms in July 21. I then got tested positive for Covid-19. In October, I got infected again. Then on the 4th of November I got my first dosage of the vaccine. I had heavy side effects. Activity Label: starting to experience symptoms"
}
\end{lstlisting}

\paragraph{Assistant Messages:} An assistant message for activity labelling consists of three to six-word summaries of events from the respective Patient Journey. Our approach is to keep the summaries close to the original text regarding the choice of words. As described in \autoref{sec:tracex}, the created activity label is later on also used to determine the event type and timestamps. To make it easier for the GPT to recognize the activity by its label in the original text, the words should be not too far off. For instance, in ~\autoref{lst:user:starttime} an activity label is used to indicate which of the timestamps present in the context is the relevant one for this request. If that activity had been summarized to \quotes{symptom onset} or \quotes{noticed first symptoms}, the model would have a harder time matching activity and timestamp because the event in question is not recognized.\\
That means the model does not learn to always use a certain structure for the summaries or a specific tense, but to adjust it to the given input instead. The focus of these examples is to provide guidance on which information is important and which is not. A user message that contains only one relevant event and spans five sentences is reduced to just one activity label, representing the one relevant event.\\\\
Assistant messages for classifying event types are just the event type itself, selected from the predefined list. Repeating this output format in every example of the training data teaches the model that no accompanying text is allowed. Otherwise, GPT-3.5 Turbo tends to include phrases like \quotes{Certainly, here is the event type for your activity}. This makes using and evaluating the results much harder, so training the model on the output format is helpful. We provide the model with diverse inputs in the user messages. Now, we use the assistant messages to teach the model which activities are related to which event type by demonstrating it in many examples. Upon completion of the training, the model is infused with our specified definition of the various event types. \\\\
We apply a similar approach to extracting the time stamps. By defining a timestamp format and repeating it in every example, the output is more reliably formatted correctly. The timestamp format required for XES files is \verb|YYYY-MM-DDTHH:mm|, so that is what we use. Aside from the formatting, the assistant messages also convey to the model how certain time specifics should be interpreted. Whenever the input in the user messages contains time-related information, the assistant message provides a correct timestamp. For example, we define that \quotes{in [month]} should default to the 15th of that month and \quotes{a few days} defaults to three days, by including many examples that demonstrate this behaviour. \\
\autoref{lst:assistant:starttime} shows what an assistant message could look like.
\begin{lstlisting}[language=json, caption={Assistant message for determining an activities start timestamp}, label={lst:assistant:starttime}, float=ht]
{"role":"assistant","content":"2021-07-15T00:00"}
\end{lstlisting}

The messages shown in ~\autoref{lst:system:starttime}, \ref{lst:user:starttime} and \ref{lst:assistant:starttime} combine to one element in the training data.\\\\

Fine-tuning, in our case, requires training data that comprises both answerable and non-answerable examples. In particular, it is crucial to provide ample examples where the context supplies sufficient information for the model to deliver an answer and, just as important, examples where the context is insufficient, making it impossible for the model to provide an answer. The ultimate goal of this juxtaposition is to teach the model to effectively differentiate between contexts where an answer can be procured and where it can not.\\
For instance, a lack of specific data, like a timestamp, might result in \quotes{N/A} being the most fitting answer the model can deduce. However, we observe that GPT-3.5 Turbo often defaults to \quotes{N/A} even when the required information is present. This necessitates that the training data meticulously demonstrates both instances where there genuinely is no answer, separated from situations where the model should provide an answer. This encourages the model to refrain from utilizing \quotes{N/A} as a response unless it is the only valid option.\\
Furthermore, the training data strikes a balance between simple and complex cases. A sufficient amount of straightforward instances is necessary to cement a clear understanding of rudimentary steps. At the same time, a sufficient amount of complicated examples is essential to equip the model with the necessary adaptability and problem-solving skills. As mentioned in \ref{par:user-messages} the context from which to extract activity labels can be a complete Patient Journey, thereby containing multiple examples for mapping sentences to activity labels. This allows us to create simple and complex examples from just one Patient Journey. A set of one to four sentences makes a relatively simple example. Three or four of these sets at once make a much more demanding yet more realistic task. The approach we implement is first to use the simple examples and then follow up with one large example, combining the simpler ones. A shortened example can be seen in~\autoref{lst:combined-example}.
\begin{lstlisting}[language=json, caption={Simple and complex examples for determining activity labels}, label={lst:combined-example}, float=p]
{"messages":[
    {"role":"system","content":..."},
    {"role":"user","content":"0: After experiencing the first symptoms of Covid-19 on 2020/09/13, I immediately isolated myself at home to prevent the possible spread of the virus to my family 1: My symptoms started with a mild fever, fatigue, and a dry cough, which progressively worsened over the following days"},
    {"role":"assistant","content":"First symptoms: Mild fever, fatigue, dry cough #0; Isolated at home #0; Symptoms worsened #1"}]}
{"messages":[
    {"role":"system","content":"..."},
    {"role":"user","content":"2: By 2020/09/15, I developed difficulty breathing and chest pain, prompting me to consult with a doctor via telemedicine 3: The doctor advised me to monitor my symptoms closely and prescribed medications to alleviate fever and cough."},
    {"role":"assistant","content":"Developed difficulty breathing, chest pain #2; Consulted doctor via telemedicine #2; Doctor prescribed medications #3"}]}
{"messages":[
    {"role":"system","content":"..."},
    {"role":"user","content":"0: After experiencing the first symptoms of Covid-19 on 2020/09/13, I immediately isolated myself at home to prevent the possible spread of the virus to my family 1: My symptoms started with a mild fever, fatigue, and a dry cough, which progressively worsened over the following days 2: By 2020/09/15, I developed difficulty breathing and chest pain, prompting me to consult with a doctor via telemedicine 3: The doctor advised me to monitor my symptoms closely and prescribed medications to alleviate fever and cough"},
    {"role":"assistant","content":"First symptoms: Mild fever, fatigue, dry cough #0; Isolated at home #0; Symptoms worsened #1; Developed difficulty breathing, chest pain #2; Consulted doctor via telemedicine #2; Doctor prescribed medications #3"}]}
\end{lstlisting}

\subsubsection{Data Sources}\label{sec:data_sources}
This chapter outlines how we acquire and prepare the data we use to fine-tune the model. In the process of acquiring training data for fine-tuning, three main steps are employed:\\\\
Firstly, sample data that can serve as input is collected. This includes gathering real-world Patient Journeys and potentially making minor adjustments to ensure their utility as examples. We need to ensure that the training data features input that the base model struggles with in order to demonstrate how the fine-tuned model should handle those cases. Additionally, we generate synthetic Patient Journeys because of their clear structure and completeness. Hence, they are well-suited for serving as basic training examples for the core aspects of extraction and validation. Furthermore, they enable us to incorporate the challenges we want to address into the training data specifically.\\\\
Secondly, we use the TracEX pipeline to establish a starting point for ground truths. This process entails incorporating few-shot prompts from TracEX into the training data, as these are already excellent examples. Then, we execute the pipeline using the collected Patient Journeys and log the intermediate results of the pipeline in a suitable JSON format that is compatible with use as training data. Each step we intend to fine-tune the model for is represented in the intermediate results. For instance, we copy the system and user message in TracEX's query to the OpenAI API and use the API's response as the assistant message. This way, each execution of TracEX's tasks produces one set of messages that can be used as training data. However, these intermediate results are merely a starting point. If TracEX could already extract the required information so well that it could be used as fine-tuning training data, fine-tuning would not be required at all. Manual checking and corrections are absolutely necessary at this stage, as errors occur, compromising the training examples. It is crucial that the training samples are free from fault. Otherwise, this could propagate the faults into the fine-tuned model. \\\\
Lastly, we request GPT-4 to do the same extraction tasks as TracEX, and also use the results as examples in the training data. Especially the more challenging examples are processed with GPT-4 to speed up the data preparation. GPT-4 outputs outperform those from GPT-3.5 Turbo and exemplify what the fine-tuned model should achieve after fine-tuning. Nonetheless, the results still need further human refining and adjustments.
% To curtail costs, we use the batch-upload feature from OpenAI to make many of the required requests to the API since it is cheaper.

\subsubsection{Parameters}
OpenAI provides three key hyperparameters that allow for customization of the fine-tuning process~\footnote{\href{https://platform.openai.com/docs/api-reference/fine-tuning/create\#fine-tuning-create-hyperparameters}{OpenAI API documentation}}: epochs, batch size, and learning rate multiplier. Epoch refers to one complete pass through the entire training dataset. Increasing it makes the model's answers comply more closely with the training data. This can also lead to overfitting, which is especially harmful for tasks that allow more varied answers. Since our set of tasks involves such tasks but also ones that require very specific answers, we opt to use two epochs. The batch size parameter determines the number of training examples used in one iteration to update the model’s parameters. Given our relatively small dataset of around 100 examples across four tasks, we choose a batch size of one to maximize the utility of each training example. It is worth noting that these 100 examples amount to about 32000 tokens or 24000 words. The learning rate multiplier adjusts the base learning rate, which controls how much the model’s weights are updated concerning the calculated error after each epoch. Due to the limited training data, we choose a learning rate multiplier of two to enable the model to learn more quickly. 

\subsection{Single-Task Fine-Tuning}\label{sec:single-task-ft}
In this chapter, we describe the process of task-specific fine-tuning GPT-3.5~Turbo for one task. For this purpose, we choose to train a model for extracting activity labels from Patient Journeys. This task is one of the most difficult among the tasks we have introduced so far and is also a more interesting subject than a traditional classification task, such as the one done in the event type classification step.\\
Extracting activity labels for events in Patient Journeys is a complex task. It requires an understanding of the condition at hand because it also implies determining which of the mentioned activities are relevant to the case. By focusing on fine-tuning an LLM for a single task, we can address a broader range of issues related to the model's performance on that specific task. By providing even more examples in the form of training data, we intend to teach the model how to handle complex cases without diverging the attention of the model by introducing further tasks, as we did in \autoref{sec:multi-task-ft}. This makes it a valuable approach.\\\\
Curating datasets is, and the data sources for this model are, very similar to the process described in \autoref{sec:data_sources} and \autoref{sec:curating_data} respectively. All approaches described for collecting examples for the task of labelling activities apply to the training of the single-task fine-tuned model as well. The sole difference is that \emph{all} examples we train the model with are specific to labelling activities.\\\\
The training data for this model contains 50 examples for the task "Activity Labelling". This is double the amount the multi-task fine-tuned model got, which amounts to approximately 16000 tokens. Because this set of training data is more specialized but still smaller overall, we choose to adjust the hyperparameters: three epochs, batch size one, and learning rate multiplier two.

\subsection*{Summary}
We start fine-tuning the GPT model for IE tasks by collecting or generating sample data from which to extract the information. Subsequently, we create ground truths for individual texts that serve as examples from which the model can learn. We leverage the extraction capabilities of TracEX to create these ground truths. For especially challenging examples, we use GPT-4 instead to expedite the process. We must manually validate and adjust the examples to ensure they are free from any fault that would otherwise harm the model's performance. We choose suitable hyperparameters depending on the task mix the model should perform and the number of total examples in the training data. We ensure that the training data addresses the base model's shortcomings by providing examples and possible answers to help the model learn how to handle challenging cases. Furthermore, we ensure that the training data addresses the individual characteristics of each task. Both high quality and a high quantity of training data are crucial. The complete fine-tuning data we curated can be checked in this repository~\footnote{https://github.com/FR-SON/Bachelor-Thesis}.