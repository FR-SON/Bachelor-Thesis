\section{Related Work}
\label{sec:related_work}
Using LLMs to extract event logs from natural language text (NLT) combines the complexity of several research disciplines: Natural Language Processing (NLP), Information Extraction (IE), Prompt Engineering, Modelling (wherein the configuration of event logs is a design decision), Software Engineering and LLM-training.\\
In this bachelor thesis, we focus explicitly on fine-tuning and the specific application of all these disciplines to extracting event logs from Patient Journeys. This use case has been relatively under-researched and is currently not documented.\\\\
In essence, extracting event logs from Patient Journeys is an IE task. IE tasks aim at extracting information from unstructured plain text. Han et al.~\cite{han_is_2023} conducted extensive research on how well ChatGPT performs in IE tasks. The outcome revealed that, even with the usage of all common prompt engineering approaches (e.g. Few, Shot, Chain of Thought), ChatGPT lags considerably behind State-of-the-Art methods. Outcomes are even worse – up to 48\% – when irrelevant information for the task is included in the context.\\
Bahak et al.~\cite{bahak_evaluating_2023} also emphasized that GPT-3.5 Turbo often hallucinates by giving context-related responses to questions, even though the given context does not contain an answer. This problem is also encountered when extracting from Patient Journeys due to often missing information, particularly time specifications. Hence, this study investigates whether fine-tuning can mitigate the problem.\\\\
Ovadia et al.~\cite{ovadia_fine-tuning_2024} explored various fine-tuning strategies (mainly unsupervised fine-tuning (USFT) and retrieval-augmented generation (RAG)) aiming to improve the processing of knowledge-based tasks. They discovered that knowledge-based tasks could be significantly improved using fine-tuned models, but RAG is more suitable for knowledge injection than USFT. Contrarily, our approach aims to enhance the model's output not by adding more knowledge but by helping the model better understand the complex task at hand. Therefore, our pursuit requires different demands on fine-tuning strategies.\\\\
\newpage
Latif et al.~\cite{latif_fine-tuning_2024} explored fine-tuned ChatGPT's potential in automated scoring of students' written work. They employed a large, diverse dataset to train their model. The result showed that the outcomes were not only better than those of the base model ChatGPT but also surpassed the performance of the then-best publicly available model, BERT. The tasks to be corrected were single and multi-label tasks, so primarily multiple-choice questions. This bachelor thesis mainly deals with tasks without predefined answer options. These tasks are even harder for the model to complete correctly and also require a different evaluation approach.\\\\
In other research areas such as Caption Rewrites~\cite{gladkoff_predictive_2023}, News Recommendations~\cite{li_exploring_2023}, or Machine Translation Evaluation~\cite{wang_mitigating_2023}, research confirmed that the application of fine-tuned models led to improved results.\\\\
A common thread in these studies is the utilization of large, well-established datasets. Extracting event logs from NLT, or Patient Journeys specifically, is still a niche sector in which such datasets do not exist. Hence, the compilation of these datasets, a crucial part of this Bachelor's Thesis, is conducted with utmost care and thoroughness to ensure the reliability of our findings.\\\\
In short, the GPT-3.5 Turbo base model is not very adept at performing IE tasks and suffers greatly from too large contexts. Depending on the goal, different fine-tuning strategies might be better suited to customize an LLM in the desired way. The increased performance of fine-tuned pre-trained transformer models in various fields of study is promising. However, the fact remains that extracting event logs from NLT involves problems that were not tackled before. The ambition of this bachelor thesis is to extend the aforementioned findings and determine if fine-tuning can resolve IE-task problems by applying training strategies. The objective of extracting high-quality event logs from Patient Journeys is used as an example throughout this thesis, as it is the focus of the underlying tool, TracEX.