\section{Fine-Tuning}\label{sec:fine}
In the following chapters, I will present an approach to fine-tuning ChatGPT 3.5 turbo, that is specialized for the task of extracting event logs from patient journeys. Part of that approach is preparing the datasets for training and validating the model. This is mainly due to the fact, that the desired application is a niche subject which results in a lack of large, established datasets. Curating and assembling the training data is a time-consuming yet crucial task in fine-tuning an LLM.\\\\
Since I use ChatGPT and the corresponding tools from OpenAI, the set of applicable fine-tuning strategies is limited. As mentioned in \ref{sec:back} there are fundamentally 3 different strategies: Supervised fine-tuning (SFT), unsupervised fine-tuning and reinforcement learning. The fine-tuning framework OpenAI provides is focused on SFT, so that is what I focus on as well. Fittingly, SFT is said to be suited for improving a model's understanding of complex tasks and increasing the reliability of correctly formatted responses, which is the purpose I use fine-tuning for.\\
Another dimension in which one can differentiate fine-tuning strategies is the number of tasks a model is fine-tuned for.\\
\emph{Multi-task fine-tuning} means training a model on multiple related tasks at the same time – within one dataset. By leveraging the commonalities of the tasks, the model can learn and understand quicker, decreasing the number of examples it needs to increase its performance in all the tasks.\\
\emph{Task-specific fine-tuning} on the other hand means training a model for only one well-defined, isolated task. This enables an even more refined understanding of the intricate details of one specific task. Especially with very complex tasks or those that require a deeper understanding of the domain, this method excels.\\\\
The individual steps included in the extraction framework of TracEX can be categorized into different types of tasks. Each type poses different challenges and has a different complexity. The classification of event types and locations requires the GPT to select the correct answer from a predefined set of choices. On top of that, the given context is relatively small. (Example) Determining the relevant activities is a much more complex task and the GPTs response is only limited by the number of words that should represent one activity. The exact words that make up the activity is up to the GPT to decide. The context for that task is larger as well, since all sentences have to be examined in context in order to determine which activities are relevant and which descriptions make up one event in the patient journey. Deriving timestamps for activities is without a doubt the hardest task. Not only is temporal information often hardly present or missing all together in real-world patient journeys, but can also take many shapes. 'On 2024/04/02', 'at the beginning of August', 'On Tuesday', 'In autumn', 'In the following days', 'Later' are all examples from real-world patient journeys, that need to be converted into XES-conform timestamps. So, adding to all the challenges involved in this type of task, is the requirement for correct formatting.

\subsection{Multi-task fine-tuning}\label{sec:multi-task}
In this chapter I will describe the process of multi-task fine-tuning ChatGPT 3.5 turbo for all the mentioned tasks labelling activities, classifying event types, classifying locations, determining start timestamps and determining end-timestamps. This strategy counteracts the fact, that the size of the datasets will always be relatively small~\ref{sec:back}, compared to the datasets used in the work presented in Chapter~\ref{related_work}. This makes it a valuable approach.
(In the following chapters, I will describe the process of task-specific fine-tuning for selected tasks, that still pose a significant challenge to the multi-task fine-tuned model.)

\subsubsection{Curating Datasets}
\paragraph{System Messages:} The system-message is in most cases identical to the system prompt used in TracEX – for two reasons:
\begin{enumerate}
    \item
        The prompts are complex, specifying the thought process the model should take, the format of the response and which aspects of the input to focus on. Showing the model how to respond to these specific instructions hopefully underlines the connection between the details of the instructions and the desired output. For example, if the instruction includes "Answer, using only one word." and the answer-message contains only one word, it should be easier for the model to understand how to action the instruction.\\
        The drawback of this approach is, that the prompts used with the fine-tuned model can not be shortened as much. They still need to contain every specification that is necessary for the base model. On the other hand, this makes the model more flexible: If a prompt contains special instructions, they will be implemented. If a prompt does not contain special instructions, no predefined formatting or similar customizations will pre present in the response.
    \item 
        Showing the model the exact same instruction over and over again, should result in the model being primed to fulfil that task, without being 'distracted' by other possible instructions. It knows only this one task, to exaggerate. Of course, a pre-trained model like ChatGPT 3.5 turbo has vast knowledge about various other tasks. Fine-tuning only changes the model on the surface level. Still, this should be considered, which is why I propose the approach of keeping the system prompts close to ones that will actually be used with the fine-tuned model.
\end{enumerate}
TODO: nochmal deutlich sagen, dass die system-messages hauptsächlich 1:1 übernommen sind

\paragraph{User messages:} Sample tasks in the user-messages should obviously also be similar to the ones the fine-tuned model will face in reality. The training data contains example inputs like they are described in Chapter 1.1: Training data for the activity labelling step is an entire patient journey. The goal is to convey which parts of the huge context are important. In order to demonstrate which aspects to keep and which to discard in the assistant-message, the entire journey is necessary.\\
TODO: *Beispiel geben dafür was wichtig ist und was nicht. ZB "unterstützung durch famiie", "habe mich entschieden mich impfen zu lassen". Es ist nur wichtig ob du es gemacht hast oder nicht. Wenn also beides enthalten ist "für impfung entschieden" und "impfung bekommen", dann ist ersteres irrelevant. Andernfalls ist es durchaus relevant, weil es vermutlich  gleichbedeutend mit "impfung erhalten" ist\\
Excerpts from journeys, four sentences or shorter, are also viable. They fulfil a different purpose. Aside from understanding the situation described in the patient journey and isolating/extracting the demanded portions, the model also needs to be trained on how to do that. Providing a multitude of shorter examples, creates a blueprint on how actives should be summarized. In active, passive, very reduced, close to the original text and so on, more on that in the next paragraph. Examples that train for the extraction of start timestamps contain an activity label, representing the event, and an excerpt of the original patient journey which the activity label was extracted from before. This is also the approach chosen in TracEX. The method delicately balances providing the GPT with sufficient context to understand the temporal relations of an event against limiting the volume of data. This ensures the performance of the GPT is not impaired due to an excess of irrelevant information for the given event~\cite{han_is_2023}.
Examples for end timestamps work similarly, additionally containing the previously extracted start timestamp. The start timestamp can be a great indication for the end timestamp. Providing it ensures, the model relies on that timestamp instead of extracting it itself.
In this way, the fine-tuning examples are structured just like the messages, the model will be prompted with.\\
User messages for the training of classifying event types are the most straight forward. They consist of just one activity label, that should be classified.

\paragraph{Assistant messages:} System messages for activity labels are 3-6 word summaries of the respective patient journey. The approach I followed is to keep the summaries close to text, regarding the choice of words. As described in Chapter~\ref{sec:back}, the created activity label is later on used to determine the event type, location and timestamps. To make it easier for the GPT to recognize the activity by its label in the original text, the words should be not too far off. TODO: Beispiel geben That means the model does not learn to always use a certain structure for the summaries or a specific tense, but to adjust it to given input. The focus of these examples is to provide guidance on which information is important and which is not.\\
System messages for classified event types are just the event type itself, from the predefined list. Repeating this output in every example of the training data teaches the model, that no accompanying text is allowed. Otherwise, ChatGPT tends to include phrases like "Certainly, here is the event type for your activity". This makes using and also evaluating the results much harder, so training the model on the output format is very helpful. Classifying the location works in the same way. A similar approach is applied for the time stamps. By defining a format for the timestamps and repeating it in every example, the output is formatted correctly a lot more reliably. The timestamp format required for XES files is \verb|YYYMMDDTHHMM|, so that is what I use.\\\\

Fine-tuning requires training data that comprises both answerable and non-answerable examples. In particular, it is crucial to provide ample examples where the context supplies sufficient information for the model to deliver an answer, and just as important, examples where the context is insufficient, making it impossible for the model to provide an answer. The ultimate goal of this juxtaposition is to teach the model to effectively differentiate between contexts where an answer can be procured and where it cannot.\\
For instance, a lack of specific data, like a timestamp, might result in 'N/A' being the most fitting option the model can deduce. However, it has been found that the baseline model often defaults to 'N/A' even when the required information is present. This necessitates that the training data meticulously demonstrates both instances where there genuinely is no answer, separated from situations where an answer should indeed be provided. This encourages the model to refrain from utilizing 'N/A' as a response unless it’s genuinely the only valid option left.

Furthermore, the training data should strike a balance between simple and complex cases. A sufficient amount of straightforward instances is necessary to cement a clear understanding of rudimentary functioning steps. At the same time, a generous presence of complicated examples is essential to equip the model with the necessary adaptability and problem-solving skills. 

\subsubsection{Data Sources}
In the process of acquiring training data for fine-tuning, three main steps are employed:\\

Firstly, sample data that can serve as input is collected. This includes gathering real-world patient journeys and potentially making minor adjustments to ensure their utility as examples. Additionally, synthetic patient journeys are generated, because of their clear structure and completeness. Hence, they are well-suited for serving as basic training examples for the core aspects of extraction and also for validation.\\

Secondly, the TraceEx Pipeline is utilized to establish a starting point. This process entails incorporating few-shot prompts from TraceEx into the training data, as these are already excellent examples. The pipeline is then executed using the collected patient journeys, and the intermediate results of the pipeline are logged in the suitable JSON format compatible with use as training data. The intermediate results represent each step that I intend to train. For instance, in the extraction of start dates, the utilized system message in the query to the ChatGPT API is copied. The user message is also taken from the request made to the API, and the API's response is used as the assistant message. This way, each execution of the pipeline produces a set of messages, that can be used as training data. However, manual checking and corrections are necessary at this stage, as errors can occur, thereby compromising the training examples. It is crucial that the training samples are free from fault, otherwise, this could propagate the faults into the fine-tuned model.\\

Lastly, ChatGPT 4 is requests to do the same extraction tasks and the results are used examples in the training data. ChatGPT 4 outputs outperform those from ChatGPT 3.5 turbo and exemplify what the fine-tuned model should achieve after fine-tuning. Nonetheless, the results still need further human refining and adjustments. In order to curtail costs, the batch-upload feature from OpenAI is used to make many of the required requests to the API.